import cv2
import asyncio
import logging
import time
from fastapi import FastAPI, APIRouter
from fastapi.responses import StreamingResponse, JSONResponse
from deepface import DeepFace
import numpy as np
from typing import Dict, Any

# --- 1. æ—¥å¿—å’Œé…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

VIDEO_STREAM_URL = "rtmp://120.46.210.148:1935/live/livestream"
MODEL_NAME = "Facenet512"
DETECTOR_BACKEND = 'opencv'


# --- 2. ä¼˜åŒ–åçš„å…¨å±€çŠ¶æ€ç®¡ç† (æ ¸å¿ƒ) ---
# ä½¿ç”¨ä¸€ä¸ªæ›´ç»“æ„åŒ–çš„çŠ¶æ€å­—å…¸
class AppState:
    def __init__(self):
        self.latest_frame: np.ndarray | None = None  # æœ€æ–°çš„åŸå§‹è§†é¢‘å¸§
        self.processed_frame: np.ndarray | None = None  # æœ€æ–°ä¸€å¸§ç»è¿‡AIå¤„ç†å¹¶ç»˜åˆ¶äº†ç»“æœçš„å¸§
        self.latest_vector: list | None = None  # æœ€æ–°æå–çš„å‘é‡
        self.last_face_location: Dict | None = None  # æœ€æ–°äººè„¸ä½ç½®
        self.is_ai_processing: bool = False  # AIæ˜¯å¦æ­£åœ¨å¤„ç†ä¸­ (å…³é”®çš„é”çŠ¶æ€)
        self.lock = asyncio.Lock()  # å¼‚æ­¥é”ï¼Œç”¨äºå®‰å…¨åœ°ä¿®æ”¹çŠ¶æ€
        self.stats: Dict[str, Any] = {  # ç»Ÿè®¡ä¿¡æ¯
            "total_frames_streamed": 0,
            "ai_tasks_triggered": 0,
            "faces_detected": 0,
            "last_detection_time": None,
            "error_count": 0,
            "fps_report": {
                "start_time": time.time(),
                "frame_count": 0,
                "fps": 0.0
            }
        }


# åˆ›å»ºå…¨å±€åº”ç”¨çŠ¶æ€å®ä¾‹
app_state = AppState()

# --- 3. FastAPI åº”ç”¨å’Œè·¯ç”± ---
router = APIRouter(prefix="/ai/facial", tags=["facial"])


# --- 4. ç‹¬ç«‹çš„ã€å¼‚æ­¥çš„AIå¤„ç†åå°ä»»åŠ¡ (æ ¸å¿ƒä¼˜åŒ–) ---
async def ai_processing_task():
    """
    ä¸€ä¸ªç‹¬ç«‹çš„åå°åç¨‹ï¼Œå¾ªç¯æ£€æŸ¥æ˜¯å¦æœ‰æ–°å¸§éœ€è¦å¤„ç†ã€‚
    è¿™ä½¿å¾—AIå¤„ç†ä¸ä¼šé˜»å¡è§†é¢‘æµçš„æ¨é€ã€‚
    """
    logger.info("ğŸ¤– AIå¤„ç†åå°ä»»åŠ¡å·²å¯åŠ¨...")
    while True:
        # å¦‚æœAIå½“å‰ç©ºé—²ï¼Œå¹¶ä¸”æœ‰æ–°çš„è§†é¢‘å¸§å¯ä»¥å¤„ç†
        if not app_state.is_ai_processing and app_state.latest_frame is not None:
            # 1. åŠ é”å¹¶æ ‡è®°AIä¸ºâ€œå¤„ç†ä¸­â€
            async with app_state.lock:
                app_state.is_ai_processing = True
                # å¤åˆ¶ä¸€ä»½å¸§è¿›è¡Œå¤„ç†ï¼Œé¿å…åç»­çš„è§†é¢‘æµä¿®æ”¹å®ƒ
                frame_to_process = app_state.latest_frame.copy()

            app_state.stats["ai_tasks_triggered"] += 1
            logger.info(f"ğŸš€ è§¦å‘ç¬¬ {app_state.stats['ai_tasks_triggered']} æ¬¡AIå¤„ç†ä»»åŠ¡...")

            try:
                # 2. å°†åŒæ­¥çš„ã€é˜»å¡çš„DeepFaceè°ƒç”¨æ”¾å…¥ä¸€ä¸ªç‹¬ç«‹çš„çº¿ç¨‹ä¸­æ‰§è¡Œ (è‡³å…³é‡è¦)
                # è¿™å¯ä»¥é˜²æ­¢é‡é‡çº§çš„AIè®¡ç®—é˜»å¡æ•´ä¸ªåº”ç”¨çš„äº‹ä»¶å¾ªç¯
                results = await asyncio.to_thread(
                    DeepFace.represent,
                    img_path=frame_to_process,
                    model_name=MODEL_NAME,
                    detector_backend=DETECTOR_BACKEND,
                    enforce_detection=True  # ç›´æ¥å¼ºåˆ¶æ£€æµ‹ï¼Œæœªæ£€æµ‹åˆ°ä¼šæŠ›å‡ºValueError
                )

                # 3. å¤„ç†æˆåŠŸçš„ç»“æœ
                if results and len(results) > 0:
                    face_info = results[0]
                    vector = face_info['embedding']
                    region = face_info['facial_area']  # DeepFaceæ–°ç‰ˆä½¿ç”¨'facial_area'

                    # å®‰å…¨åœ°æ›´æ–°å…¨å±€çŠ¶æ€
                    async with app_state.lock:
                        app_state.latest_vector = vector
                        app_state.last_face_location = region
                        app_state.stats["faces_detected"] += 1
                        app_state.stats["last_detection_time"] = time.strftime("%Y-%m-%d %H:%M:%S")

                    logger.info(f"âœ… AIå¤„ç†æˆåŠŸï¼Œæ£€æµ‹åˆ°äººè„¸ï¼Œå‘é‡ç»´åº¦: {len(vector)}")

                    # 4. åœ¨å¤„ç†å¸§çš„å‰¯æœ¬ä¸Šç»˜åˆ¶ç»“æœï¼Œç”¨äºè§†é¢‘æµæ˜¾ç¤º
                    cv2.rectangle(frame_to_process, (region['x'], region['y']),
                                  (region['x'] + region['w'], region['y'] + region['h']), (0, 255, 0), 2)
                    cv2.putText(frame_to_process, "Face Detected", (region['x'], region['y'] - 10),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                    app_state.processed_frame = frame_to_process

            except ValueError:
                # DeepFaceåœ¨enforce_detection=Trueä¸”æœªæ£€æµ‹åˆ°äººè„¸æ—¶ä¼šæŠ›å‡ºæ­¤å¼‚å¸¸
                logger.info("âšª AIå¤„ç†å®Œæˆï¼Œå½“å‰å¸§æœªæ£€æµ‹åˆ°äººè„¸ã€‚")
                async with app_state.lock:
                    # å¯ä»¥é€‰æ‹©æ¸…ç©ºä¸Šæ¬¡çš„å‘é‡ï¼Œæˆ–ä¿ç•™
                    app_state.latest_vector = None
                    app_state.last_face_location = None
                # å½“æœªæ£€æµ‹åˆ°äººè„¸æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥è®©processed_frameæ˜¾ç¤ºåŸå§‹å›¾åƒ
                app_state.processed_frame = frame_to_process

            except Exception as e:
                logger.error(f"âŒ AIå¤„ç†ä»»åŠ¡å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
                app_state.stats["error_count"] += 1

            finally:
                # 5. æ— è®ºæˆåŠŸä¸å¦ï¼Œéƒ½è¦é‡Šæ”¾é”ï¼Œæ ‡è®°AIä¸ºç©ºé—²
                async with app_state.lock:
                    app_state.is_ai_processing = False

        # æ— è®ºæ˜¯å¦å¤„ç†ï¼Œéƒ½çŸ­æš‚ä¼‘çœ ï¼Œé¿å…ç©ºè½¬æ¶ˆè€—CPU
        await asyncio.sleep(0.05)  # ä¼‘çœ 50æ¯«ç§’


# --- 5. è§†é¢‘æµç”Ÿæˆå™¨ (ç°åœ¨å˜å¾—éå¸¸è½»é‡) ---
async def video_stream_generator():
    """
    è§†é¢‘æµç”Ÿæˆå™¨ï¼Œç°åœ¨åªè´Ÿè´£ä»è§†é¢‘æºè¯»å–å¸§ï¼Œå¹¶æ¨é€æœ€æ–°çš„â€œå·²å¤„ç†å¸§â€ã€‚
    """
    cap = cv2.VideoCapture(VIDEO_STREAM_URL)
    if not cap.isOpened():
        logger.error(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æµ: {VIDEO_STREAM_URL}")
        return

    logger.info("âœ… è§†é¢‘æµè¿æ¥æˆåŠŸï¼Œå¼€å§‹æ¨æµ...")

    while True:
        ret, frame = cap.read()
        if not ret:
            logger.warning("âš ï¸ è§†é¢‘å¸§è¯»å–å¤±è´¥ï¼Œå°è¯•é‡è¿...")
            cap.release()
            await asyncio.sleep(2)
            cap = cv2.VideoCapture(VIDEO_STREAM_URL)
            if not cap.isOpened():
                logger.error("âŒ é‡è¿å¤±è´¥ï¼Œç»ˆæ­¢æ¨æµã€‚")
                break
            continue

        # 1. å®‰å…¨åœ°æ›´æ–°å…¨å±€çš„æœ€æ–°åŸå§‹å¸§
        async with app_state.lock:
            app_state.latest_frame = frame
            app_state.stats["total_frames_streamed"] += 1

        # 2. å†³å®šè¦æ˜¾ç¤ºçš„å¸§ (æ ¸å¿ƒé€»è¾‘)
        # å¦‚æœæœ‰å¤„ç†è¿‡çš„å¸§ï¼Œå°±ç”¨å®ƒï¼›å¦åˆ™ç”¨åŸå§‹å¸§
        display_frame = app_state.processed_frame if app_state.processed_frame is not None else frame

        # 3. è®¡ç®—å¹¶æ›´æ–°FPS
        stats = app_state.stats["fps_report"]
        stats["frame_count"] += 1
        elapsed_time = time.time() - stats["start_time"]
        if elapsed_time >= 1.0:  # æ¯ç§’æ›´æ–°ä¸€æ¬¡FPS
            stats["fps"] = stats["frame_count"] / elapsed_time
            # logger.info(f"Streaming FPS: {stats['fps']:.1f}")
            stats["start_time"] = time.time()
            stats["frame_count"] = 0

        # åœ¨è¦æ˜¾ç¤ºçš„å¸§ä¸Šç»˜åˆ¶FPSä¿¡æ¯
        cv2.putText(display_frame, f"FPS: {stats['fps']:.1f}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255),
                    2)

        # 4. ç¼–ç å¹¶æ¨é€
        (flag, encodedImage) = cv2.imencode(".jpg", display_frame)
        if not flag:
            continue

        yield (b'--frame\r\n' b'Content-Type: image/jpeg\r\n\r\n' + bytearray(encodedImage) + b'\r\n')

        # ç¨å¾®ç­‰å¾…ï¼Œè®©å‡ºCPUç»™å…¶ä»–ä»»åŠ¡ï¼Œè¿™ä¸ªå€¼å¯ä»¥æ ¹æ®æµçš„æµç•…åº¦å¾®è°ƒ
        await asyncio.sleep(1 / 60)  # å°è¯•åŒ¹é…60fpsçš„æ¨é€é€Ÿç‡


# --- 6. FastAPIåº”ç”¨ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ ---
@router.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶ï¼Œåˆ›å»ºå¹¶å¯åŠ¨åå°AIä»»åŠ¡"""
    logger.info("åº”ç”¨å¯åŠ¨ï¼Œåˆ›å»ºAIåå°ä»»åŠ¡...")
    # asyncio.create_task åœ¨åå°â€œç‚¹ç‡ƒâ€ä¸€ä¸ªåç¨‹ï¼Œè®©å®ƒç‹¬ç«‹è¿è¡Œ
    asyncio.create_task(ai_processing_task())


# --- 7. API è·¯ç”±å®šä¹‰ (ä¿æŒä¸å˜æˆ–å¾®è°ƒ) ---
@router.get("/")
def read_root():
    return {"message": "äººè„¸è¯†åˆ«AIæœåŠ¡", "docs": "/docs"}


@router.get("/video_feed")
async def video_feed():
    return StreamingResponse(video_stream_generator(), media_type="multipart/x-mixed-replace; boundary=frame")


@router.get("/get_latest_vector")
async def get_latest_vector():
    if app_state.latest_vector:
        return JSONResponse(content={
            "status": "success",
            "model": MODEL_NAME,
            "data": {
                "vector": app_state.latest_vector,
                "face_location": app_state.last_face_location
            }
        })
    else:
        return JSONResponse(status_code=404, content={"status": "error", "message": "æš‚æ— å¯ç”¨çš„äººè„¸ç‰¹å¾å‘é‡ã€‚"})


@router.get("/get_stats")
async def get_stats():
    return JSONResponse(content={"status": "success", "data": app_state.stats})


# ä¸»åº”ç”¨å¼•å…¥è·¯ç”±
app = FastAPI(title="å®æ—¶äººè„¸è¯†åˆ«AIæœåŠ¡")
app.include_router(router)